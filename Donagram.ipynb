{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUtbycZxw-xr"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import git\n",
        "from git import Repo\n",
        "from PIL import Image\n",
        "import io\n",
        "import subprocess\n",
        "\n",
        "last_update_id = None\n",
        "TOKEN = ''  #creds\n",
        "chat_id = ''  #creds\n",
        "\n",
        "\n",
        "def send_telegram_message(message):\n",
        "    url = f\"https://api.telegram.org/bot{TOKEN}/sendMessage?chat_id={chat_id}&text={message}\"\n",
        "    response = requests.get(url)\n",
        "    print(f\"Sent message: {message}, Response: {response.json()}\")\n",
        "\n",
        "def send_telegram_image(image_path):\n",
        "    url = f\"https://api.telegram.org/bot{TOKEN}/sendPhoto\"\n",
        "    with open(image_path, 'rb') as image_file:\n",
        "        files = {'photo': image_file}\n",
        "        data = {'chat_id': chat_id}\n",
        "        response = requests.post(url, files=files, data=data)\n",
        "    print(f\"Sent image: {image_path}, Response: {response.json()}\")\n",
        "\n",
        "def get_updates(offset=None):\n",
        "    url = f\"https://api.telegram.org/bot{TOKEN}/getUpdates\"\n",
        "    params = {'offset': offset, 'timeout': 30}\n",
        "    response = requests.get(url, params=params).json()\n",
        "    return response.get('result', [])\n",
        "\n",
        "def clear_previous_messages():\n",
        "    global last_update_id\n",
        "    updates = get_updates()\n",
        "    if updates:\n",
        "        last_update_id = updates[-1]['update_id'] + 1\n",
        "    print(f\"Cleared previous messages. Last update ID: {last_update_id}\")\n",
        "\n",
        "def get_cuda_options():\n",
        "    p = subprocess.run(['nvidia-smi','-q'], capture_output=True, text=True)\n",
        "    pret=p.returncode\n",
        "    if pret!=0:\n",
        "        print(\"Device doesnt have GPU or CUDA drivers error\")\n",
        "        send_telegram_message(\"Device doesnt have GPU or CUDA drivers error\")\n",
        "        return\n",
        "    pop=p.stdout\n",
        "    for popline in pop.splitlines():\n",
        "      send_telegram_message(popline)\n",
        "\n",
        "\n",
        "def preprocess_image(imgbytes):\n",
        "    image_stream=io.BytesIO(imgbytes)\n",
        "    image=Image.open(image_stream).convert('L')\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((28, 28)),  # Resize to the input size expected by the model\n",
        "        transforms.ToTensor(),  # Convert image to tensor\n",
        "        transforms.Normalize((0.5,),(0.5,))  # Normalize with ImageNet mean and std\n",
        "    ])\n",
        "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "    return image\n",
        "\n",
        "def test_model(fuid):\n",
        "    global model\n",
        "    url=f\"http://api.telegram.org/bot{TOKEN}/getFile?file_id={fuid}\"\n",
        "    response=requests.get(url)\n",
        "    fpath=response.json()['result']['file_path']\n",
        "    url=f\"http://api.telegram.org/file/bot{TOKEN}/{fpath}\"\n",
        "    response=requests.get(url)\n",
        "    image_tensor=preprocess_image(response.content)\n",
        "    model.eval()\n",
        "    res=model(image_tensor)\n",
        "    print(res)\n",
        "    predicted_class = res.argmax(dim=1).item()\n",
        "    print(f'Predicted class: {predicted_class}')\n",
        "    send_telegram_message(f'Predicted class: {predicted_class}')\n",
        "\n",
        "\n",
        "def request_user_input(prompt):\n",
        "    global last_update_id\n",
        "    send_telegram_message(prompt)\n",
        "    start_time = time.time()\n",
        "    timeout = 300\n",
        "    while time.time() - start_time < timeout:\n",
        "        updates = get_updates(last_update_id)\n",
        "        for update in updates:\n",
        "            last_update_id = update['update_id'] + 1\n",
        "            if 'message' in update and 'text' in update['message']:return update['message']['text'].lower()\n",
        "            if 'message' in update and 'photo' in update['message']:test_model(update['message']['photo'][0]['file_id'])\n",
        "        time.sleep(1)\n",
        "    send_telegram_message(\"No input received within 5 minutes. Using default value.\")\n",
        "    return None\n",
        "\n",
        "def get_hyperparameters():\n",
        "    choice = request_user_input(\"Do you want to input hyperparameters? (yes/no)\")\n",
        "    if choice == 'yes':\n",
        "        learning_rate =float(request_user_input(\"Enter learning rate (e.g., 0.001):\") or 0.001)\n",
        "        batch_size = int(request_user_input(\"Enter batch size (e.g., 64):\") or 64)\n",
        "        num_epochs = int(request_user_input(\"Enter number of epochs (e.g., 2):\") or 2)\n",
        "        hidden_size = int(request_user_input(\"Enter hidden layer size (e.g., 512):\") or 512)\n",
        "    else:\n",
        "        learning_rate = 0.001\n",
        "        batch_size = 64\n",
        "        num_epochs = 2\n",
        "        hidden_size = 512\n",
        "    send_telegram_message(f\"Using hyperparameters: learning_rate={learning_rate}, batch_size={batch_size}, num_epochs={num_epochs}, hidden_size={hidden_size}\")\n",
        "    return learning_rate, batch_size, num_epochs, hidden_size\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(nn.Linear(28*28, hidden_size),nn.ReLU(),nn.Linear(hidden_size, 10))\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.linear_relu_stack(x)\n",
        "\n",
        "def train_model(num_epochs,train_loader,model,criterion,optimizer):\n",
        "    model.train()\n",
        "    epoch_losses=[]\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss=0\n",
        "        for _, (data,targets) in enumerate(train_loader):\n",
        "            outputs=model(data)\n",
        "            loss=criterion(outputs, targets)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss+=loss.item()\n",
        "        epoch_loss/=len(train_loader)\n",
        "        epoch_losses.append(epoch_loss)\n",
        "        print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}')\n",
        "        send_telegram_message(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}')\n",
        "    return epoch_losses\n",
        "\n",
        "def check_file_sizes():\n",
        "    max_file_size = 100*1024*1024\n",
        "    acceptable_files = []\n",
        "    for root, dirs, files in os.walk('.'):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if os.path.getsize(file_path) <= max_file_size:acceptable_files.append(file_path)\n",
        "    return acceptable_files\n",
        "\n",
        "def push_to_github(repo_url, is_private):\n",
        "    try:\n",
        "        if os.path.exists('.git'):repo = Repo('.')\n",
        "        else:\n",
        "            repo = Repo.init('.')\n",
        "            repo.create_remote('origin', url=repo_url)\n",
        "        repo.git.add(A=True)\n",
        "        repo.index.commit(\"Update from Telegram bot\")\n",
        "        origin = repo.remote('origin')\n",
        "        origin.push()\n",
        "        send_telegram_message(\"Successfully pushed to GitHub repository.\")\n",
        "    except Exception as e:send_telegram_message(f\"Error pushing to GitHub: {str(e)}\")\n",
        "\n",
        "# Clear previous messages\n",
        "clear_previous_messages()\n",
        "\n",
        "def proginit():\n",
        "    global model\n",
        "    learning_rate, batch_size, num_epochs, hidden_size = get_hyperparameters()\n",
        "    transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
        "    train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    model = SimpleNet(hidden_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    send_telegram_message(\"Model training has started.\")\n",
        "\n",
        "    epoch_losses = train_model(num_epochs, train_loader, model, criterion, optimizer)\n",
        "    final_loss = epoch_losses[-1]\n",
        "\n",
        "    send_telegram_message(f\"Training complete. Final loss: {final_loss:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(epoch_losses, marker='o', linestyle='-', color='b')\n",
        "    plt.title('Training Loss Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.savefig('training_loss_plot.png')\n",
        "    plt.close()\n",
        "\n",
        "    send_telegram_image('training_loss_plot.png')\n",
        "\n",
        "while True:\n",
        "    proginit()\n",
        "    # GitHub integration\n",
        "    use_github = request_user_input(\"Do you want to use GitHub? (yes/no)\")\n",
        "    if use_github == 'yes':\n",
        "        acceptable_files = check_file_sizes()\n",
        "        send_telegram_message(f\"Files acceptable for GitHub push: {', '.join(acceptable_files)}\")\n",
        "        push_decision = request_user_input(\"Do you want to push these files to GitHub? (yes/no)\")\n",
        "        if push_decision == 'yes':\n",
        "            repo_url = request_user_input(\"Enter your GitHub repository URL:\")\n",
        "            is_private = request_user_input(\"Is this a private repository? (yes/no)\")=='yes'\n",
        "            push_to_github(repo_url, is_private)\n",
        "\n",
        "    command = request_user_input(\"Enter 'rerun' to train again with new parameters, or 'stop' to end the program, 'cuda' to get CUDA status and stop, or an image to test model:\")\n",
        "    if command == \"stop\":\n",
        "        send_telegram_message(\"Training stopped by user command.\")\n",
        "        break\n",
        "    elif command == \"rerun\":\n",
        "        send_telegram_message(\"Rerunning the training with new parameters.\")\n",
        "        continue\n",
        "    elif command==\"cuda\":\n",
        "        get_cuda_options()\n",
        "        break\n",
        "    else:\n",
        "        send_telegram_message(\"Invalid command. Stopping the program.\")\n",
        "        break\n"
      ]
    }
  ]
}